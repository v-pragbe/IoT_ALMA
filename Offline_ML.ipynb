{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7701365-e4e9-495c-955d-5a434ca131e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b37ff-cbc2-4ba6-81ff-1a16fc26acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/promisea/ALMA/EdgeIIoT/EdgeIIoT.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "X = df.drop(['Attack_type'], axis=1)\n",
    "y = df['Attack_type']\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef94b5b-1b57-489c-bdf7-8472fcbbb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers\n",
    "results = {}\n",
    "start_overall = time.perf_counter()  # Start measuring total execution time\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    mem_usage = max(memory_usage((clf.fit, (X_train, y_train)), interval=1))  # Less frequent checks to reduce overhead\n",
    "    train_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    y_pred = clf.predict(X_test)\n",
    "    test_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Testing Time\": test_time,\n",
    "        \"Memory Usage\": mem_usage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277b44fd-09bc-4b62-be8f-5275ebe4a7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of the EdgeIIoT dataset...\n",
      "Random Forest:\n",
      "    Accuracy: 0.9913\n",
      "    F1 Score: 0.9832\n",
      "    Training Time: 4.9541\n",
      "    Testing Time: 0.1909\n",
      "    Memory Usage: 548.1719\n",
      "KNN:\n",
      "    Accuracy: 0.9616\n",
      "    F1 Score: 0.9251\n",
      "    Training Time: 0.7304\n",
      "    Testing Time: 3.7649\n",
      "    Memory Usage: 548.2812\n",
      "SVM:\n",
      "    Accuracy: 0.9113\n",
      "    F1 Score: 0.7830\n",
      "    Training Time: 486.5974\n",
      "    Testing Time: 64.2922\n",
      "    Memory Usage: 1060.2812\n",
      "Decision Tree:\n",
      "    Accuracy: 0.9928\n",
      "    F1 Score: 0.9862\n",
      "    Training Time: 1.0978\n",
      "    Testing Time: 0.0050\n",
      "    Memory Usage: 663.0156\n",
      "Logistic Regression:\n",
      "    Accuracy: 0.8951\n",
      "    F1 Score: 0.7171\n",
      "    Training Time: 2.0722\n",
      "    Testing Time: 0.0037\n",
      "    Memory Usage: 682.7969\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"The results of the EdgeIIoT dataset...\" )\n",
    "for classifier, metrics in results.items():\n",
    "    print(f\"{classifier}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cb3679-cf14-4c53-a1c6-fceeee772adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/promisea/ALMA/CIC/CIC_IoT_2023.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec6a84c-b93e-48f5-992b-9fd99049f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers\n",
    "results = {}\n",
    "start_overall = time.perf_counter()  # Start measuring total execution time\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    mem_usage = max(memory_usage((clf.fit, (X_train, y_train)), interval=1))  # Less frequent checks to reduce overhead\n",
    "    train_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    y_pred = clf.predict(X_test)\n",
    "    test_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Testing Time\": test_time,\n",
    "        \"Memory Usage\": mem_usage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594afff7-7389-41ef-bf04-7e1914712a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of the CIC IoT dataset...\n",
      "Random Forest:\n",
      "    Accuracy: 0.9968\n",
      "    F1 Score: 0.9653\n",
      "    Training Time: 17.1536\n",
      "    Testing Time: 0.2161\n",
      "    Memory Usage: 1179.4219\n",
      "KNN:\n",
      "    Accuracy: 0.9912\n",
      "    F1 Score: 0.9084\n",
      "    Training Time: 0.8447\n",
      "    Testing Time: 31.8610\n",
      "    Memory Usage: 1147.2188\n",
      "SVM:\n",
      "    Accuracy: 0.9928\n",
      "    F1 Score: 0.9256\n",
      "    Training Time: 172.9238\n",
      "    Testing Time: 63.4193\n",
      "    Memory Usage: 1367.0781\n",
      "Decision Tree:\n",
      "    Accuracy: 0.9957\n",
      "    F1 Score: 0.9532\n",
      "    Training Time: 2.4182\n",
      "    Testing Time: 0.0074\n",
      "    Memory Usage: 376.7812\n",
      "Logistic Regression:\n",
      "    Accuracy: 0.9889\n",
      "    F1 Score: 0.8733\n",
      "    Training Time: 4.1608\n",
      "    Testing Time: 0.0095\n",
      "    Memory Usage: 435.6094\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"The results of the CIC IoT dataset...\" )\n",
    "for classifier, metrics in results.items():\n",
    "    print(f\"{classifier}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fb0f42-5450-4f01-a374-677c9af69edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/promisea/ALMA/EHMS/ehms.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cf34a4-2aa5-4ee3-a28b-30460c802e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers\n",
    "results = {}\n",
    "start_overall = time.perf_counter()  # Start measuring total execution time\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    mem_usage = max(memory_usage((clf.fit, (X_train, y_train)), interval=1))  # Less frequent checks to reduce overhead\n",
    "    train_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    y_pred = clf.predict(X_test)\n",
    "    test_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Testing Time\": test_time,\n",
    "        \"Memory Usage\": mem_usage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2c7fc2-f0b7-43fc-b592-1640ef4ab009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of the WUSTL-EHMS dataset...\n",
      "Random Forest:\n",
      "    Accuracy: 0.9367\n",
      "    F1 Score: 0.8203\n",
      "    Training Time: 3.5744\n",
      "    Testing Time: 0.0345\n",
      "    Memory Usage: 483.6094\n",
      "KNN:\n",
      "    Accuracy: 0.9387\n",
      "    F1 Score: 0.8490\n",
      "    Training Time: 1.3883\n",
      "    Testing Time: 0.3568\n",
      "    Memory Usage: 483.7188\n",
      "SVM:\n",
      "    Accuracy: 0.9307\n",
      "    F1 Score: 0.7936\n",
      "    Training Time: 2.0528\n",
      "    Testing Time: 0.7612\n",
      "    Memory Usage: 692.6562\n",
      "Decision Tree:\n",
      "    Accuracy: 0.9749\n",
      "    F1 Score: 0.9429\n",
      "    Training Time: 0.9394\n",
      "    Testing Time: 0.0006\n",
      "    Memory Usage: 692.6562\n",
      "Logistic Regression:\n",
      "    Accuracy: 0.9297\n",
      "    F1 Score: 0.7920\n",
      "    Training Time: 0.8302\n",
      "    Testing Time: 0.0007\n",
      "    Memory Usage: 693.5625\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"The results of the WUSTL-EHMS dataset...\" )\n",
    "for classifier, metrics in results.items():\n",
    "    print(f\"{classifier}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d1d9e5-fe17-402f-b5da-36c0c07e2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"scada_modified.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1913c1b2-1d3b-42a0-92dc-d0340232d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers\n",
    "results = {}\n",
    "start_overall = time.perf_counter()  # Start measuring total execution time\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    mem_usage = max(memory_usage((clf.fit, (X_train, y_train)), interval=1))  # Less frequent checks to reduce overhead\n",
    "    train_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    start_time = time.perf_counter()  # Real time measurement starts\n",
    "    y_pred = clf.predict(X_test)\n",
    "    test_time = time.perf_counter() - start_time  # Real time measurement ends\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Testing Time\": test_time,\n",
    "        \"Memory Usage\": mem_usage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2827f20d-6828-43e8-9727-53764f8fe064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of  the WUSTL-SCADA dataset...\n",
      "Random Forest:\n",
      "    Accuracy: 1.0000\n",
      "    F1 Score: 1.0000\n",
      "    Training Time: 2.7049\n",
      "    Testing Time: 0.0418\n",
      "    Memory Usage: 713.0938\n",
      "KNN:\n",
      "    Accuracy: 0.9997\n",
      "    F1 Score: 0.9997\n",
      "    Training Time: 0.8123\n",
      "    Testing Time: 0.4177\n",
      "    Memory Usage: 713.2656\n",
      "SVM:\n",
      "    Accuracy: 0.9887\n",
      "    F1 Score: 0.9887\n",
      "    Training Time: 6.3741\n",
      "    Testing Time: 2.6045\n",
      "    Memory Usage: 1039.4531\n",
      "Decision Tree:\n",
      "    Accuracy: 1.0000\n",
      "    F1 Score: 1.0000\n",
      "    Training Time: 0.6592\n",
      "    Testing Time: 0.0010\n",
      "    Memory Usage: 1027.8281\n",
      "Logistic Regression:\n",
      "    Accuracy: 0.9821\n",
      "    F1 Score: 0.9821\n",
      "    Training Time: 0.9978\n",
      "    Testing Time: 0.0026\n",
      "    Memory Usage: 1029.1719\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"The results of  the WUSTL-SCADA dataset...\" )\n",
    "for classifier, metrics in results.items():\n",
    "    print(f\"{classifier}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148ace2-a4b8-4878-821c-d8423075c96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river",
   "language": "python",
   "name": "river"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
